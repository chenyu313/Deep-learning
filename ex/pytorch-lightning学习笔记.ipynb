{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch-Lightning学习笔记"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pytorch-lighting（简称pl），它其实就是一个轻量级的PyTorch库，用于高性能人工智能研究的轻量级PyTorch包装器。缩放你的模型，而不是样板。  \n",
    "Pytorch-lightning可以非常简洁得构建深度学习代码。但是其实大部分人用不到很多复杂得功能。而pl有时候包装得过于深了，用的时候稍微有一些不灵活。通常来说，在你的模型搭建好之后，大部分的功能都会被封装在一个叫trainer的类里面。一些比较麻烦但是需要的功能通常如下, 通过pl就可以很好的实现：  \n",
    "* 保存checkpoints\n",
    "* 输出log信息\n",
    "* resume training 即重载训练，我们希望可以接着上一次的epoch继续训练\n",
    "* 记录模型训练的过程(通常使用tensorboard)\n",
    "* 设置seed，即保证训练过程可以复制"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "实现流程：\n",
    "* 初始化 def __ init __(self) \n",
    "* 训练training_step(self, batch, batch_idx) \n",
    "* 校验validation_step(self, batch, batch_idx) \n",
    "* 测试 test_step(self, batch, batch_idx)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightningModuel\n",
    "LightningModule将你的PyTorch代码组织成6个部分:\n",
    "* initialization (__ init__ and setup())：初始化\n",
    "* Train Loop (training_step())：训练\n",
    "* Validation Loop (validation_step())：验证\n",
    "* Validation Loop (validation_step())：测试\n",
    "* Prediction Loop (predict_step())：预测\n",
    "* Optimizers and LR Schedulers (configure_optimizers())：优化器和学习率调整程序"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "框架：  \n",
    "net = MyLightningModuleNet()  \n",
    "trainer = Trainer()  \n",
    "trainer.fit(net)  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 简单实现\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导包\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "import pytorch_lightning as pl\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __ init __（初始化）\n",
    "构造函数中，像常见的 torch.nn.Module 一样，我们定义好模型的层。由于是最简实例，这里只有一层线性层，将手写数字图像映射为输出 logits。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### forward（前向传播）\n",
    "由于是继承自 torch.nn.Module，因此实现 forward 方法是必须的。forward 方法要完成模型的前向过程，这里直接调用 __ init__ 中定义好的线性层，完成模型前向过程。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train_dataloader（训练数据集获取）\n",
    "train_dataloader 方法也是最简实现中必须的，它的功能是获取训练集的 DataLoader。这里我们返回 MNIST 数据集的 DataLoader。dataloader 的获取也可以不在类内实现，而是在 fit 时传入，后面会介绍。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training_step（训练步骤）\n",
    "training_step 是是 LigtningModule 的核心方法，它定义了一个训练步中需要做的事情。在深度学习的训练步中，最核心的事情就是模型前向，得到结果，计算损失，反向传播，更新参数，这几步在 pytorch 中都有对应的方法供调用。但是在 pytorch lightning 中，我们只需要进行模型前向，并返回必要的信息即可。在最简实现中，我们只需返回损失。\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### configure_optimizer（配置优化器）\n",
    "在 training_step 中，我们只需返回损失，这意味着模型的反向传播和参数更新过程由 pytorch lightning 帮我们完成了。虽然这个过程可以有框架自己完成，但是我们还是要指定参数更新所用的优化器，在很多模型中，优化器、学习率等超参数设置对结果影响很大。在最简实现中，我们设置好学习率，并返回一个 Adam 优化器。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 简易的pl模型\n",
    "class LitModel(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Linear(28 * 28, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.relu(self.l1(x.view(x.size(0), -1)))\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=0.02)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name | Type   | Params\n",
      "--------------------------------\n",
      "0 | l1   | Linear | 7.9 K \n",
      "--------------------------------\n",
      "7.9 K     Trainable params\n",
      "0         Non-trainable params\n",
      "7.9 K     Total params\n",
      "0.031     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a9be65aa7b741c9b43d52b5000b663b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=2` reached.\n"
     ]
    }
   ],
   "source": [
    "# 开始训练\n",
    "train_loader = DataLoader(MNIST(os.getcwd(), download=True, transform=transforms.ToTensor())) # 获取数据\n",
    "trainer = pl.Trainer(max_epochs=2) #初始化训练器\n",
    "model = LitModel() #初始化模型\n",
    "\n",
    "trainer.fit(model, train_dataloaders=train_loader) #开始训练"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上代码实现了一个最简的 pytorch lightning 训练过程。这足以体现出 pytorch lightning 的简洁、易用。但是，显然这个最简实现缺少了很多东西，比如验证、测试、日志打印、模型保存等。接下来，我们将实现相对完整但依旧简洁的 pytorch lightning 模型开发过程。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 补充\n",
    "我们还缺少验证和测试的步骤：\n",
    "* 模型定义 _ init_\n",
    "* 前向计算 forward\n",
    "* 训练/ 验证/ 测试 （training_step/ validation_step/ test_step）\n",
    "* 训练/ 验证/ 测试结束后（training_step_end/validation_step_end/test_step_end）\n",
    "* 选用优化器 (configure_optimizers)\n",
    "* 数据加载器 (train_dataloader, val_dataloader, test_dataloader)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightningModule自带工具\n",
    "* log：Tensorboard 损失/指标日志保存和查看，不要自己定义，直接用即可。用法非常简单，将要记录的值传入:self.log('train loss', loss)\n",
    "* print:LightningModule 提供的 print 只打印一次\n",
    "* freeze:冻结所有权重以供预测时候使用。仅当已经训练完成且后面只测试时使用\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 拓展实例\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name | Type   | Params\n",
      "--------------------------------\n",
      "0 | fc   | Linear | 7.9 K \n",
      "--------------------------------\n",
      "7.9 K     Trainable params\n",
      "0         Non-trainable params\n",
      "7.9 K     Total params\n",
      "0.031     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62e4ecd03fc74fcfa1d3f3b9eb53c4dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f656d88980b24a3f841ccf3d07750574",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1752192c2f3d44bebb2a524127708ae4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d189d34ce924a2caf3095f7149f2c68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "706b5524923a410b8ae2102232f84e9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2c2915475bc48fbb5d1c2a39c6cc346",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23dff5a6e7714b33b69e402423cb4839",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at d:\\Github_code\\Deep-learning\\ex\\lightning_logs\\version_9\\checkpoints\\epoch=4-step=9375.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at d:\\Github_code\\Deep-learning\\ex\\lightning_logs\\version_9\\checkpoints\\epoch=4-step=9375.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33d3243819af40f7aecb0878e4a43dbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{}]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "import pytorch_lightning as pl\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class MNISTModel(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(28 * 28, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.relu(self.fc(x.view(-1, 28 * 28)))\n",
    "\n",
    "    def training_step(self, batch, batch_nb):\n",
    "        # REQUIRED\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "        self.log('train_loss', loss, on_step=False, on_epoch=True)\n",
    "        return {'loss': loss}\n",
    "\n",
    "    def validation_step(self, batch, batch_nb):\n",
    "        # OPTIONAL\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "        pred = y_hat.argmax(dim=1, keepdim=True)\n",
    "        correct = pred.eq(y.view_as(pred)).sum().item()\n",
    "        acc = correct / x.shape[0]\n",
    "        self.log('val_acc', acc, on_step=False, on_epoch=True)\n",
    "        self.log('val_loss', loss, on_step=False, on_epoch=True)\n",
    "        return {'val_loss': loss, 'val_acc': acc}\n",
    "\n",
    "   \n",
    "\n",
    "    def test_step(self, batch, batch_nb):\n",
    "        # OPTIONAL\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "        return {'test_loss': loss}\n",
    "\n",
    "   \n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        # REQUIRED\n",
    "        return torch.optim.Adam(self.parameters(), lr=0.02)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        # REQUIRED\n",
    "        return DataLoader(MNIST(os.getcwd(), train=True, download=True, transform=transforms.ToTensor()), batch_size=32)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        # OPTIONAL\n",
    "        return DataLoader(MNIST(os.getcwd(), train=False, download=True, transform=transforms.ToTensor()), batch_size=32)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        # OPTIONAL\n",
    "        return DataLoader(MNIST(os.getcwd(), train=False, download=True, transform=transforms.ToTensor()), batch_size=32)\n",
    "\n",
    "model = MNISTModel()\n",
    "trainer = pl.Trainer(\n",
    "        max_epochs=10,\n",
    "        callbacks=[pl.callbacks.EarlyStopping( monitor=\"val_loss\", patience=3)]\n",
    ")\n",
    "trainer.fit(model)\n",
    "trainer.test()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 参考\n",
    "[pytorch lightning最简上手](https://blog.csdn.net/weixin_44966641/article/details/127827124)  \n",
    "[Pytorch Lightning 完全攻略](https://zhuanlan.zhihu.com/p/319810661)  \n",
    "[pytorch-lightning入门](https://blog.csdn.net/u014264373/article/details/117021901)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuralkg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
